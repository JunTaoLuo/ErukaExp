{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG7GpCZyv21r"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gncnPS4-v17s",
        "outputId": "b2260e98-176a-4245-bbfe-e12e5cf53151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 0s (12.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 128275 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (8.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (23.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.5.3)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.7/299.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: contourpy, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.3\n",
            "    Uninstalling matplotlib-3.5.3:\n",
            "      Successfully uninstalled matplotlib-3.5.3\n",
            "Successfully installed contourpy-1.0.7 matplotlib-3.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n",
            "Collecting pillow\n",
            "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed pillow-9.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install matplotlib --upgrade\n",
        "!pip install -U pillow\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import math\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#from deslant_img import deslant_img\n",
        "import imutils\n",
        "import fnmatch\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from skimage.transform import hough_line, hough_line_peaks, probabilistic_hough_line\n",
        "from skimage.feature import canny\n",
        "from skimage.draw import line\n",
        "\n",
        "# Hyperparameters\n",
        "img_width = 2100\n",
        "img_height = 1650\n",
        "line_dedup_threshold = 10\n",
        "crop_left_margin = 100\n",
        "crop_top_margin = 40\n",
        "crop_dim = 200\n",
        "min_horizontal_gap = 35\n",
        "min_horizontal_intercept = 22\n",
        "max_first_horizontal_intercept = 50\n",
        "default_first_horizontal_intercept = 15\n",
        "\n",
        "segment_width, segment_height = 100, 25\n",
        "segment_corners = np.array([(0, segment_height), (segment_width, segment_height), (segment_width, 0), (0, 0)]).astype(np.float32)\n",
        "\n",
        "# Parameters\n",
        "root_dir = \"/content/gdrive/MyDrive/ErukaTraining/OC/\"\n",
        "input_dir = f\"{root_dir}raw/\"\n",
        "output_dir = f\"{root_dir}images/\"\n",
        "error_dir = f\"{root_dir}processing_logs/segmentation_errors/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KmEZPh-XuKQ"
      },
      "source": [
        "# Data Structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUw3bQQVXthW"
      },
      "outputs": [],
      "source": [
        "class Point:\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.coords_int = [round(x), round(y)]\n",
        "        self.coords_float = [x, y]\n",
        "\n",
        "class Line:\n",
        "    def __init__(self, x, y, slope):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.slope = slope\n",
        "        self.is_horizontal = abs(slope) < 1\n",
        "        # Intercept with the center of the image which is at (crop_dim/2, crop_dim/2)\n",
        "        if self.is_horizontal:\n",
        "            self.intercept = self.y - ((self.x - crop_dim/2) * self.slope)\n",
        "        else:\n",
        "            self.intercept = self.x - ((self.y - crop_dim/2) / self.slope)\n",
        "\n",
        "class Box:\n",
        "    def __init__(self, tl, tr, bl, br):\n",
        "        self.tl = tl\n",
        "        self.tr = tr\n",
        "        self.bl = bl\n",
        "        self.br = br\n",
        "\n",
        "        minx = min(tl.x, tr.x, bl.x, br.x)\n",
        "        maxx = max(tl.x, tr.x, bl.x, br.x)\n",
        "        miny = min(tl.y, tr.y, bl.y, br.y)\n",
        "        maxy = max(tl.y, tr.y, bl.y, br.y)\n",
        "\n",
        "        self.height = maxy - miny\n",
        "        self.width = maxx - minx\n",
        "\n",
        "        self.polygon_int = np.array([bl.coords_int, br.coords_int, tr.coords_int, tl.coords_int])\n",
        "        self.polygon_float = np.array([bl.coords_float, br.coords_float, tr.coords_float, tl.coords_float], dtype=np.float32)\n",
        "\n",
        "        self.center = Point((minx+maxx)/2, (miny+maxy)/2)\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"tl: ({self.tl.x},{self.tl.y}) tr: ({self.tr.x},{self.tr.y}) bl: ({self.bl.x},{self.bl.y}) br: ({self.br.x},{self.br.y})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmrCcWJfu8FB"
      },
      "source": [
        "TODO:\n",
        "- Cases where building is not detected\n",
        "- Test stability for more images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZhf8DW2YMCS"
      },
      "source": [
        "# Line Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0GPEJzZu8FD"
      },
      "outputs": [],
      "source": [
        "# Merge horizontal lines that are close together\n",
        "def dedup_horizontal_lines(raw_lines):\n",
        "    raw_lines.sort(key=lambda l: l.intercept)\n",
        "    lines=[]\n",
        "    merge_count = 1\n",
        "    for line in raw_lines:\n",
        "        if len(lines) == 0 or abs(line.intercept - lines[-1].intercept) > line_dedup_threshold:\n",
        "            lines.append(line)\n",
        "            merge_count = 1\n",
        "        else:\n",
        "            lines[-1] = Line(crop_dim/2, (lines[-1].intercept*merge_count + line.intercept)/(merge_count+1), (lines[-1].slope*merge_count + line.slope)/(merge_count+1))\n",
        "            merge_count += 1\n",
        "    return lines\n",
        "\n",
        "# Ensure the first horizontal line is valid\n",
        "def filter_horizontal_lines(raw_lines):\n",
        "    lines=[]\n",
        "    prev_intercept = 0.0\n",
        "    for i, line in enumerate(raw_lines):\n",
        "        # Remove lines outside of margin\n",
        "        if line.intercept < min_horizontal_intercept:\n",
        "            continue\n",
        "        lines.append(line)\n",
        "    \n",
        "    if lines[0].intercept > max_first_horizontal_intercept:\n",
        "        lines.insert(0, Line(crop_dim/2, default_first_horizontal_intercept, 0))\n",
        "\n",
        "    return lines\n",
        "\n",
        "def dedup_vertical_lines(raw_lines):\n",
        "    raw_lines.sort(key=lambda l: l.intercept)\n",
        "    lines=[]\n",
        "    merge_count = 1\n",
        "    for line in raw_lines:\n",
        "        if len(lines) == 0 or abs(line.intercept - lines[-1].intercept) > line_dedup_threshold:\n",
        "            lines.append(line)\n",
        "            merge_count = 1\n",
        "        else:\n",
        "            lines[-1] = Line((lines[-1].intercept*merge_count + line.intercept)/(merge_count+1), crop_dim/2, line.slope) # Don't average the slopes\n",
        "            merge_count += 1\n",
        "    return lines\n",
        "\n",
        "def detect_lines(img_cropped):\n",
        "    # Preprocessing for Hough\n",
        "    gray = cv2.cvtColor(img_cropped,cv2.COLOR_BGR2GRAY)\n",
        "    thresh, thresh_image = cv2.threshold(gray, 165, 255, cv2.THRESH_BINARY)\n",
        "    gray = cv2.convertScaleAbs(thresh_image) # converting the scale\n",
        "    edges = cv2.Canny(gray, 0, 200)\n",
        "\n",
        "    # Parameters\n",
        "    thresh = 10\n",
        "    min_distance = 15\n",
        "\n",
        "    # Perform hough transformation\n",
        "    dimx, dimy = edges.shape\n",
        "    #diagonal = np.sqrt(dimx**2 + dimy**2)\n",
        "    #thresh = int(thresh * diagonal)\n",
        "    # TODO: only scan near horizontal and near vertical lines\n",
        "    tested_angles = np.linspace(-np.pi, np.pi, 360, endpoint = False)\n",
        "\n",
        "    # Apply hough lines to retrieve all possible lines\n",
        "    h, theta, d = hough_line(edges, theta = tested_angles)\n",
        "    hspace, angles, dists = hough_line_peaks(h, theta, d, thresh, min_distance)\n",
        "    \n",
        "    lines = []\n",
        "    for _, angle, dist in zip(hspace, angles, dists):\n",
        "        (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
        "        angle_abs = abs(angle)\n",
        "        # We are only looking for nearly vertical and horizontal lines so use a pi/8 margin\n",
        "        if np.pi/8 < angle_abs and angle_abs < 3*np.pi/8:\n",
        "            continue\n",
        "        slope = np.tan(angle + np.pi/2)\n",
        "        lines.append(Line(x0, y0, slope))\n",
        "\n",
        "    h_lines = [line for line in lines if line.is_horizontal]\n",
        "    v_lines = [line for line in lines if not line.is_horizontal]\n",
        "\n",
        "    deduped = dedup_horizontal_lines(h_lines)\n",
        "    # print(f\"Before filtering: {len(deduped)}\")\n",
        "    deduped = filter_horizontal_lines(deduped)\n",
        "    # print(f\"After filtering: {len(filtered)}\")\n",
        "\n",
        "    # return h_lines, v_lines\n",
        "    return deduped, dedup_vertical_lines(v_lines)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HjkUdFqZd2Z"
      },
      "source": [
        "# Resolve bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3i5MgZ6u8FE"
      },
      "outputs": [],
      "source": [
        "## Finding the intersection points\n",
        "\n",
        "# To avoid some precision bugs\n",
        "def bound_slope(slope):\n",
        "    return min(max(slope, -1000), 1000)\n",
        "\n",
        "def intersection(line1, line2):\n",
        "    A = np.array([[bound_slope(-line1.slope), 1], \n",
        "                  [bound_slope(-line2.slope), 1]])\n",
        "    b = np.array([[line1.y - bound_slope(line1.slope)*line1.x], \n",
        "                  [line2.y - bound_slope(line2.slope)*line2.x]])\n",
        "    \n",
        "    x = np.linalg.lstsq(A, b, rcond=-1)[0]\n",
        "    return Point(x[0][0], x[1][0]) # use lstsq to solve Ax = b, not inv() which is unstable\n",
        "\n",
        "# Function sourced from this answer: https://stackoverflow.com/a/70371736\n",
        "\n",
        "def hough_inter(theta1, rho1, theta2, rho2):\n",
        "    A = np.array([[np.cos(theta1), np.sin(theta1)], \n",
        "                  [np.cos(theta2), np.sin(theta2)]])\n",
        "    b = np.array([rho1, rho2])\n",
        "    \n",
        "    return np.linalg.lstsq(A, b)[0] # use lstsq to solve Ax = b, not inv() which is unstable\n",
        "\n",
        "def resolve_bounding_boxes(h_lines, v_lines):\n",
        "    # Now loop through all combinations of lines, only checking for intersections if they are of different types\n",
        "    intersections = []\n",
        "\n",
        "    for h_line in h_lines:\n",
        "        for v_line in v_lines:\n",
        "            intersections.append(intersection(h_line, v_line))\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    for i, h_line in enumerate(h_lines):\n",
        "        bl = intersection(h_line, v_lines[0])\n",
        "        br = intersection(h_line, v_lines[1])\n",
        "        if i > 0:\n",
        "            boxes.append(Box(tl, tr, bl, br))\n",
        "        tl = Point(bl.x, bl.y)\n",
        "        tr = Point(br.x, br.y)\n",
        "    \n",
        "    return intersections, boxes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N1YxO1OUJmQ"
      },
      "source": [
        "#Batch process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaIXhKx4T_iN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "89d5aef1-6a38-45f5-a3c3-64c40398159c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3326\u001b[0;31m                     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3327\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-875552f25f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input files: {len(all_files)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/gdrive/MyDrive/ErukaTraining/OC/raw/'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Get initial position, this should be the center of the \"Buildings\" cell\n",
        "def get_initial_position(img):\n",
        "    d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
        "\n",
        "    building_index, total_index, land_index, valuation_index = -999, -999, -999, -999\n",
        "\n",
        "    for index, text in enumerate(d['text']):\n",
        "        if text.lower() == \"buildings\":\n",
        "            building_index = index\n",
        "        if text.lower() == \"total\":\n",
        "            total_index = index\n",
        "        if text.lower() == 'land':\n",
        "            land_index = index\n",
        "        if text.lower() == 'valuations':\n",
        "            valuation_index = index\n",
        "\n",
        "    if building_index == -999: \n",
        "        raise RuntimeError(\"could not find buildings cell\")\n",
        "\n",
        "    return Point(d['left'][building_index] + d['width'][building_index]/2, d['top'][building_index] + d['height'][building_index]/2)\n",
        "\n",
        "def interpolate_row_coordinate(a, b, rows):\n",
        "    new_x = (a.x * (rows-1) + b.x)/rows\n",
        "    new_y = (a.y * (rows-1) + b.y)/rows\n",
        "    return Point(new_x, new_y)\n",
        "\n",
        "def get_next_position(center, img, out_dir, i):\n",
        "\n",
        "    top = int(center.y - crop_top_margin)\n",
        "    left = int(center.x - crop_left_margin)\n",
        "\n",
        "    img_cropped = img[top:top+crop_dim, left:left+crop_dim]\n",
        "    h_lines, v_lines = detect_lines(img_cropped)\n",
        "\n",
        "    plt.clf()\n",
        "    plt.imshow(img_cropped)\n",
        "    for line in h_lines:\n",
        "        plt.axline((line.x, line.y), slope=line.slope, color='red')\n",
        "    for line in v_lines:\n",
        "        plt.axline((line.x, line.y), slope=line.slope, color='blue')\n",
        "        \n",
        "    if len(h_lines) < 3:\n",
        "        # plt.savefig(f\"{out_dir}{i}_lines.jpg\")\n",
        "        raise RuntimeError(\"could not detect at least 3 horizontal lines\")\n",
        "    \n",
        "    if len(v_lines) != 2:\n",
        "        # plt.savefig(f\"{out_dir}{i}_lines.jpg\")\n",
        "        print(\"Warning: could not detect exactly 2 vertical lines, using defaults\")\n",
        "        v_lines = [Line(10, crop_dim/2, 1000), Line(190, crop_dim/2, 1000)]\n",
        "    \n",
        "    intersections, boxes = resolve_bounding_boxes(h_lines, v_lines)\n",
        "\n",
        "    next_box = boxes[1]\n",
        "    \n",
        "    if next_box.height < 35:\n",
        "        print(f\"Warning: box of height {next_box.height} is likely due to a extra horizontal line\")\n",
        "        next_box = boxes[2]\n",
        "\n",
        "    if next_box.height > 70:\n",
        "        print(f\"Warning: box of height {next_box.height} is likely due to a missing horizontal line\")\n",
        "        rows = round(next_box.height/50)\n",
        "        next_box = Box(next_box.tl, next_box.tr, interpolate_row_coordinate(next_box.tl, next_box.bl, rows), interpolate_row_coordinate(next_box.tr, next_box.br, rows))\n",
        "\n",
        "\n",
        "    if not (math.isclose(next_box.height, 50, rel_tol=0.2) and math.isclose(next_box.width, 180, rel_tol=0.2)):\n",
        "        # plt.savefig(f\"{out_dir}{i}_lines.jpg\")\n",
        "        raise RuntimeError(f\"box dimensions {next_box.width}x{next_box.height} is unexpected\")\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(next_box.polygon_float, segment_corners)\n",
        "    out = cv2.warpPerspective(img_cropped, M,(segment_width, segment_height))\n",
        "\n",
        "    return Point(center.x - crop_left_margin + next_box.center.x, center.y - crop_top_margin + next_box.center.y), out\n",
        "\n",
        "all_files = set(os.listdir(input_dir))\n",
        "print(f\"Input files: {len(all_files)}\")\n",
        "\n",
        "existing_files = set(os.listdir(output_dir))\n",
        "print(f\"Existing files: {len(existing_files)}\")\n",
        "\n",
        "error_files = fnmatch.filter(os.listdir(error_dir), \"*.csv\")\n",
        "error_set = set()\n",
        "for error_file in error_files:\n",
        "  error_file_df = pd.read_csv(f'{error_dir}{error_file}', converters={'file': str})\n",
        "  error_file_set = set(error_file_df['file'].values.flatten())\n",
        "  error_set.update(error_file_set)\n",
        "print(f\"Errors: {len(error_set)}\")\n",
        "\n",
        "missing_files = list(all_files - existing_files - error_set)\n",
        "print(len(missing_files))\n",
        "print(f\"Files to process: {len(missing_files)}\")\n",
        "\n",
        "batch = 0\n",
        "batch_total = 1\n",
        "batch_files = missing_files[batch*len(missing_files)//batch_total:(batch+1)*len(missing_files)//batch_total]\n",
        "errors = []\n",
        "box_count = 0\n",
        "\n",
        "for file_i, file in enumerate(batch_files):\n",
        "    if not file.endswith(\".jpg\"):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing file ({file_i}/{len(batch_files)}): {file}\")\n",
        "\n",
        "    if (file_i + 1) % 1000 == 0:\n",
        "        errors_df = pd.DataFrame(errors, columns=['file', 'message'])\n",
        "        errors_df.to_csv(f\"{error_dir}{datetime.now().strftime('%Y-%m-%d-%H-%M')}.csv\", index=False)\n",
        "\n",
        "    img = cv2.imread(f'{input_dir}{file}')\n",
        "    try:\n",
        "      img = cv2.resize(img, (img_width, img_height))\n",
        "    except:\n",
        "        print(f\"Processing failed for {file}: resize error\\n\")\n",
        "        errors.append([file, \"resize error\"])\n",
        "        continue\n",
        "    try:\n",
        "        center = get_initial_position(img)\n",
        "        print(f\"Center: ({center.x},{center.y})\")\n",
        "    except RuntimeError as error:\n",
        "        print(f\"Processing failed for {file}: {str(error)}\\n\")\n",
        "        errors.append([file, str(error)])\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        center, segmented_img = get_next_position(center, img, output_dir, 0)\n",
        "        box_count += 1\n",
        "    except RuntimeError as error:\n",
        "        print(f\"Processing failed for {file}: {str(error)}\\n\")\n",
        "        errors.append([file, str(error)])\n",
        "        continue\n",
        "    except IndexError as error:\n",
        "        print(f\"Processing failed for {file}: {str(error)}\\n\")\n",
        "        errors.append([file, str(error)])\n",
        "        continue\n",
        "\n",
        "    cv2.imwrite(f\"{output_dir}{file}\", segmented_img)\n",
        "\n",
        "errors_df = pd.DataFrame(errors, columns=['file', 'message'])\n",
        "errors_df.to_csv(f\"{error_dir}{datetime.now().strftime('%Y-%m-%d-%H-%M')}.csv\", index=False)\n",
        "print(f\"Box count: {box_count}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-KmEZPh-XuKQ",
        "wZhf8DW2YMCS",
        "3HjkUdFqZd2Z"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "ab1a610369466872a6bf5153616b411187d6a3d0837424a5e62a0321071151d5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}